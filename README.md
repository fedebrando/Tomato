# Tomato

Let us indicate the root project folder with `/`.

## Setup
Follow these steps to set up the project.

1. Clone this repo on the UniPr cluster
    ```bash
    git clone https://github.com/fedebrando/Tomato.git
    ```
1. Run the following two commands to use conda
    ```bash
    module load miniconda3
    source "$CONDA_PREFIX/etc/profile.d/conda.sh"
    ```

1. Create a conda virtual environment using the YAML file: from root `/` run the following command replacing `env_name` with a new one that you prefer
    ```bash
    conda env create -f environment.yml -n env_name
    ```

## Training
The entry point of training is in the script `/src/train.py`. To run a train, open the bash script `/train_launch.bash` and modify the following main parts.

- **Job name** (at line 9). It is also the name of the output file generated by the cluster.
- **Conda environment name** (at line 21). Replace the name written in the script with your environment one.
- **Training starter command** (at line 23). Configure your line-command optional parameters as you prefer, following the table below.

    | Param  | Description | Example (default)     |
    |-------|----|-----------|
    |`--epochs`|number of epochs|`--epochs=500`|
    |`--bs`|number of elements in batch size|`--bs=16`|
    |`--print_every`|print losses every N iteration|`--print_every=5`|
    |`--early_stop`|number of non improvements on validation accuracy to stop training|`--early_stop=5`|
    |`--lr`|learning rate|`--lr=1e-3`|
    |`--opt`|optimizer used for training|`--opt=Adam`|
    |`--aug_flip`|data augmentation with flip|`--aug_flip=0`|
    |`--aug_rotate`|data augmentation with rotate|`--aug_rotate=0`|
    |`--aug_jitter`|data augmentation with color jitter|`--aug_jitter=0`|
    |`--aug_crop`|data augmentation with crop|`--aug_crop=0`|
    |`--refine_model`|refine model of path received|`--refine_model=""`|

Now, you can start training running the command below from `/`.
```bash
sbatch train_launch.bash
```
Once the training is finished, you can find
- the **best model** and the last model weights at `/../models/<model_name>`;
- the **training statistics** at `/../runs/<model_name>/train`, visible running the command below from `/`.
    ```bash
    tensorboard --logdir=../runs
    ```

## Testing
For a model testing, the entry point is in the script `/src/test.py`. To test your model, open the bash script `/test_launch.bash` and modify the following main parts.

- **Job name** (at line 9). It is also the name of the output file generated by the cluster.
- **Conda environment name** (at line 21). Replace the name written in the script with your environment one.
- **Training starter command** (at line 23). Configure your line-command optional parameters as you prefer, following the table below.

    | Param  | Description | Example (default)     |
    |-------|----|-----------|
    |`--model_name`|name of the model to be tested|`--model_name=best`|
    |`--save_preds`|save some model predictions|-|

Now, you can start testing running the command below from `/`.
```bash
sbatch test_launch.bash
```

Once the testing is finished, you can find
- the **test statistics** at `/../runs/<model_name>/test`, visible running the command below from `/`.
    ```bash
    tensorboard --logdir=../runs
    ```
- some **model predictions** at `/../runs/<model_name>/inference` if indicated with `--save_preds` in the starter command.

## Notes
To change percentages for the validation set or the test set, modify their relative constants in the script `/src/params.py`.

The **best-so-far model** is saved with its relative statistic information in `/best_model`. You can show the latter running the command below from `/`.
```bash
tensorboard --logdir=best_model/stats
```
